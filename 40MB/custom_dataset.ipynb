{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "custom_dataset.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moh53/Graduation-Project-FMS/blob/NN-models/40MB/custom_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7djV55rTrXtB",
        "outputId": "b405d66f-c135-4c98-88cc-930c8b29e7a6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3eQ1uGhr73Q"
      },
      "source": [
        "import numpy as np\n",
        "data_X=np.load('drive/MyDrive/X.npy')\n",
        "data_Y=np.load('drive/MyDrive/Y.npy')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91PI0Gx5sEzC"
      },
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as T\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.utils import save_image\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ywKxbo9sJ83"
      },
      "source": [
        "image_size=50\n",
        "class IDCdataset(Dataset):\n",
        "  def __init__(self, X, y):\n",
        "        'Initialization'\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "  def __len__(self):\n",
        "        'Denotes the total number of samples'\n",
        "        return len(self.X)\n",
        "  def __getitem__(self, index):\n",
        "        'Generates one sample of data'\n",
        "        # Select sample\n",
        "        image = self.X[index]\n",
        "        y = self.y[index]\n",
        "        X = self.transform(image)\n",
        "        #y = self.transform(label)\n",
        "        return X ,y\n",
        "  transform = T.Compose([\n",
        "        T.ToPILImage(),\n",
        "        T.Resize(image_size),\n",
        "        T.ToTensor()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7M8e2uTAthz8"
      },
      "source": [
        "Dataset=IDCdataset(data_X,data_Y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGHDvYnMtp7F",
        "outputId": "b7d2de32-67c7-4b47-a275-1f2eb8e785db"
      },
      "source": [
        "print(len(Dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5547\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfHs5BU5tsaA",
        "outputId": "56f8a9c2-2819-4fd2-d4f4-1330d34b655c"
      },
      "source": [
        "print(Dataset[3759])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[[0.5765, 0.4667, 0.5059,  ..., 0.5333, 0.7098, 0.6078],\n",
            "         [0.6627, 0.6078, 0.5255,  ..., 0.5020, 0.5255, 0.7059],\n",
            "         [0.4471, 0.5412, 0.5137,  ..., 0.5647, 0.6078, 0.6941],\n",
            "         ...,\n",
            "         [0.8118, 0.8314, 0.8235,  ..., 0.4392, 0.5725, 0.5333],\n",
            "         [0.8824, 0.9216, 0.9294,  ..., 0.6078, 0.6980, 0.7294],\n",
            "         [0.7137, 0.8824, 0.9176,  ..., 0.5412, 0.7059, 0.7725]],\n",
            "\n",
            "        [[0.3922, 0.3216, 0.3412,  ..., 0.3961, 0.5451, 0.4431],\n",
            "         [0.4431, 0.4549, 0.3608,  ..., 0.3569, 0.3843, 0.5020],\n",
            "         [0.2667, 0.3608, 0.3490,  ..., 0.4118, 0.4549, 0.4902],\n",
            "         ...,\n",
            "         [0.5216, 0.5647, 0.5412,  ..., 0.2745, 0.3725, 0.3647],\n",
            "         [0.7647, 0.8784, 0.8902,  ..., 0.4000, 0.4863, 0.5373],\n",
            "         [0.3922, 0.7647, 0.9020,  ..., 0.3373, 0.3176, 0.3843]],\n",
            "\n",
            "        [[0.5608, 0.4980, 0.5216,  ..., 0.5412, 0.6667, 0.5961],\n",
            "         [0.6000, 0.6314, 0.5333,  ..., 0.5255, 0.5529, 0.6471],\n",
            "         [0.4745, 0.5373, 0.5373,  ..., 0.5922, 0.6118, 0.6314],\n",
            "         ...,\n",
            "         [0.6157, 0.6706, 0.6510,  ..., 0.4510, 0.5490, 0.5373],\n",
            "         [0.8157, 0.8941, 0.9020,  ..., 0.5882, 0.6392, 0.6902],\n",
            "         [0.5137, 0.8235, 0.9137,  ..., 0.4941, 0.4745, 0.5294]]]), 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhlGjM11y8au"
      },
      "source": [
        "batch_size = 16\n",
        "transformed_dataset = IDCdataset(data_X,data_Y)\n",
        "train_dl = DataLoader(transformed_dataset, batch_size, shuffle=True, num_workers=2, pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKzicXP6zLdx"
      },
      "source": [
        "validation_split = .2\n",
        "shuffle_dataset = True\n",
        "random_seed= 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4R_wFFHUz8Ao"
      },
      "source": [
        "# Creating data indices for training and validation splits:\n",
        "dataset_size = len(Dataset)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split * dataset_size))\n",
        "train_indices, val_indices = indices[split:], indices[:split]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bmBmB9Pz8ir"
      },
      "source": [
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "# Creating PT data samplers and loaders:\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIFFskJE0AFo",
        "outputId": "2b0d0222-6afa-4134-edd2-6b3a344ebcb7"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(Dataset, batch_size=batch_size,\n",
        "                                           sampler=train_sampler,)\n",
        "validation_loader = torch.utils.data.DataLoader(Dataset, batch_size=batch_size,\n",
        "                                                sampler=valid_sampler)\n",
        "print(len(train_loader))\n",
        "print(len(validation_loader))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "278\n",
            "70\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wadhcHBq0Gcl"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7h6vchwV0QHd"
      },
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear( 3 * 50 * 50 , 32),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(32 , 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64 , 2)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQ_KqP990T10"
      },
      "source": [
        "optimiser = optim.SGD(model.parameters(), lr=1e-2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVQYBoph0WrR"
      },
      "source": [
        "loss = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8Ss4wiV0f5x",
        "outputId": "3e802c3d-99c2-449a-e2bb-4927fa8ee4b9"
      },
      "source": [
        "n_epochs = 15 \n",
        "batch_size = 16\n",
        "for epoch in range(n_epochs):\n",
        "    losses = list()\n",
        "    for batch in train_loader:\n",
        "      'x is the images and the labels in the batch'\n",
        "      x ,y = batch\n",
        "      'reshape the image though they fit in the input NN as 3 * 50 * 50'\n",
        "      x = x.view(x.size(0), -1)\n",
        "      'x.shape[16, 7500] = [batch_size, 3*50*50]'\n",
        "      'y.shape[16] indicate the label'\n",
        "      \n",
        "      l = model(x)\n",
        "      'print(l.shape)-->[16,2]'\n",
        "      \n",
        "      'cuz the wants BCEWithLogitsLoss takes the l(logit) and y(target) be in the same shape  ' \n",
        "      j = loss(l[:,0], y.float())\n",
        "\n",
        "      model.zero_grad()\n",
        "\n",
        "      j.backward()\n",
        "\n",
        "      optimiser.step()\n",
        "\n",
        "      losses.append(j.item()\n",
        "      )\n",
        "    print(f'Epoch{epoch + 1}, train loss : {torch.tensor(losses).mean():.2f}')\n",
        "       \n",
        "    losses = list()\n",
        "\n",
        "    for batch in validation_loader:\n",
        "      x, y = batch\n",
        "      \n",
        "      'x = torch.div(x,255) if x is unit8 not float as expected '\n",
        "      x = x.view(x.size(0), -1)\n",
        "\n",
        "      with torch.no_grad():\n",
        "          l = model(x)\n",
        "      \n",
        "      'cuz the wants BCEWithLogitsLoss takes the l(logit) and y(target) be in the same shape  ' \n",
        "\n",
        "      j = loss(l[:,0] ,y.float())\n",
        "      \n",
        "      losses.append(j.item())\n",
        "    \n",
        "    print(f'Epoch{epoch + 1}, validation loss : {torch.tensor(losses).mean():.2f}')\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch1, train loss : 0.51\n",
            "Epoch1, validation loss : 1.04\n",
            "Epoch2, train loss : 0.50\n",
            "Epoch2, validation loss : 0.31\n",
            "Epoch3, train loss : 0.51\n",
            "Epoch3, validation loss : 1.35\n",
            "Epoch4, train loss : 0.50\n",
            "Epoch4, validation loss : 0.62\n",
            "Epoch5, train loss : 0.49\n",
            "Epoch5, validation loss : 0.53\n",
            "Epoch6, train loss : 0.49\n",
            "Epoch6, validation loss : 0.92\n",
            "Epoch7, train loss : 0.49\n",
            "Epoch7, validation loss : 0.85\n",
            "Epoch8, train loss : 0.50\n",
            "Epoch8, validation loss : 1.72\n",
            "Epoch9, train loss : 0.49\n",
            "Epoch9, validation loss : 1.55\n",
            "Epoch10, train loss : 0.48\n",
            "Epoch10, validation loss : 0.37\n",
            "Epoch11, train loss : 0.49\n",
            "Epoch11, validation loss : 0.93\n",
            "Epoch12, train loss : 0.48\n",
            "Epoch12, validation loss : 2.94\n",
            "Epoch13, train loss : 0.49\n",
            "Epoch13, validation loss : 0.84\n",
            "Epoch14, train loss : 0.48\n",
            "Epoch14, validation loss : 1.12\n",
            "Epoch15, train loss : 0.48\n",
            "Epoch15, validation loss : 0.64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRQdFOwzsF4T"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}