{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "concat_dataset_40MB.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moh53/Graduation-Project-FMS/blob/NN-models/40MB/concat_dataset_40MB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s34lrn9_AxI1"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlPfsEZmBEO7",
        "outputId": "0b6fefaa-d04a-4eca-cf0a-bab856acec02"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-TNm8XHBGv8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZ-lWTbkNQnL"
      },
      "source": [
        "import numpy as np\n",
        "data_X=np.load('drive/MyDrive/X.npy')\n",
        "data_Y=np.load('drive/MyDrive/Y.npy')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWWTEOxqNQb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "967c0b5f-1d39-4878-f657-80f2f255f6f7"
      },
      "source": [
        "data_IDC_X = torch.from_numpy(data_X)\n",
        "data_IDC_Y = torch.from_numpy(data_Y)\n",
        "print(data_IDC_X.shape)\n",
        "print(data_IDC_Y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5547, 50, 50, 3])\n",
            "torch.Size([5547])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZcoAgNDNQMf",
        "outputId": "6e18ff18-9e47-4440-87d4-e2ebf14b3edc"
      },
      "source": [
        "imgs0 = data_IDC_X[data_Y==0] # (0 = no IDC, 1 = IDC)\n",
        "imgs1 = data_IDC_X[data_Y==1]\n",
        "print(\"THE SHAPE OF NEGATIVE SAMPLES\", imgs0.shape)\n",
        "#print(imgs0)\n",
        "print(\"THE SHAPE OF POSITIVE SAMPLES\", imgs1.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "THE SHAPE OF NEGATIVE SAMPLES torch.Size([2759, 50, 50, 3])\n",
            "THE SHAPE OF POSITIVE SAMPLES torch.Size([2788, 50, 50, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVo5TB5jBge8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGf37FIgNPm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41305037-bc0f-4baa-f1b2-480046d92c41"
      },
      "source": [
        "\n",
        "concate_dataset = torch.utils.data.ConcatDataset([imgs0, imgs1])\n",
        "print(type(data_IDC_X))\n",
        "print(data_IDC_X.shape)\n",
        "type(concate_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.Size([5547, 50, 50, 3])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.utils.data.dataset.ConcatDataset"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpgpoIHoBlbO"
      },
      "source": [
        "\n",
        "datasets = [imgs0,imgs1]\n",
        "for i in range(3):\n",
        "    datasets.append(torch.utils.data.TensorDataset(torch.arange(i*10, (i+1)*10)))\n",
        "\n",
        "dataset = torch.utils.data.ConcatDataset([imgs0,imgs1])\n",
        "loader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    batch_size=2\n",
        ")\n",
        "\n",
        "#for data in loader:\n",
        "  #  print(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5MO-LdEDVlz"
      },
      "source": [
        "validation_split = .2\n",
        "shuffle_dataset = True\n",
        "random_seed= 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1tH89vMN-cc"
      },
      "source": [
        "# Creating data indices for training and validation splits:\n",
        "dataset_size = len(concate_dataset)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split * dataset_size))\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyuNEbVqHE_c"
      },
      "source": [
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "# Creating PT data samplers and loaders:\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42uql-oWHU88",
        "outputId": "165dc234-ad50-44e8-f33b-89331a1125e7"
      },
      "source": [
        "\n",
        "train_loader = torch.utils.data.DataLoader(concate_dataset, batch_size=32,\n",
        "                                           sampler=train_sampler,)\n",
        "validation_loader = torch.utils.data.DataLoader(concate_dataset, batch_size=32,\n",
        "                                                sampler=valid_sampler)\n",
        "print(len(train_loader))\n",
        "print(len(validation_loader))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "139\n",
            "35\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvgSOWItHcTG"
      },
      "source": [
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mpv02nXOHpoV"
      },
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear( 3 * 50 * 50 , 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64 , 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64 , 2)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztFhYu8VSBAG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOJvI50lHsSr"
      },
      "source": [
        "optimiser = optim.SGD(model.parameters(), lr=1e-2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARCIFjYVHvP4"
      },
      "source": [
        "loss = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyRAOdXGHyYR",
        "outputId": "67afbd57-35de-4015-96b2-24c4e7712a0e"
      },
      "source": [
        "n_epochs = 15 \n",
        "batch_size = 20 \n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    losses = list()\n",
        "    # X is a torch Variable\n",
        "    #permutation = torch.randperm(data_IDC_X.size()[0])\n",
        "\n",
        "    for batch_size in train_loader:\n",
        "        #optimizer.zero_grad()\n",
        "\n",
        "        #indices = permutation[i:i+batch_size]\n",
        "        batch_x, batch_y = data_IDC_X[indices], data_IDC_Y[indices]\n",
        "        b = batch_x.size(0)\n",
        "        batch_x = batch_x.view(b,-1)\n",
        "        x = batch_x.view(batch_x.size(0), -1)\n",
        "        #x =torchvision.transforms.functional.to_tensor(x)\n",
        "        x = torch.div(x,255)\n",
        "        l = model(x)\n",
        "        j = loss(l , batch_y)\n",
        "        model.zero_grad()\n",
        "        j.backward()\n",
        "        optimiser.step()\n",
        "        losses.append(j.item())\n",
        "    print(f'Epoch{epoch + 1}, train loss : {torch.tensor(losses).mean():.2f}')\n",
        "       \n",
        "    losses = list()\n",
        "       \n",
        "    \n",
        "    for batch_size in validation_loader:\n",
        "        #optimizer.zero_grad()\n",
        "\n",
        "        #indices = permutation[i:i+batch_size]\n",
        "        batch_x, batch_y = data_IDC_X[indices], data_IDC_Y[indices]\n",
        "        b = batch_x.size(0)\n",
        "        batch_x = batch_x.view(b,-1)\n",
        "        x = batch_x.view(batch_x.size(0), -1)\n",
        "        #x =torchvision.transforms.functional.to_tensor(x)\n",
        "        with torch.no_grad():\n",
        "            x = torch.div(x,255)\n",
        "        l = model(x)\n",
        "        j = loss(l , batch_y)\n",
        "        losses.append(j.item())\n",
        "    print(f'Epoch{epoch + 1}, validation loss : {torch.tensor(losses).mean():.2f}')\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch1, train loss : 0.56\n",
            "Epoch1, validation loss : 0.56\n",
            "Epoch2, train loss : 0.55\n",
            "Epoch2, validation loss : 0.55\n",
            "Epoch3, train loss : 0.55\n",
            "Epoch3, validation loss : 0.55\n",
            "Epoch4, train loss : 0.55\n",
            "Epoch4, validation loss : 0.54\n",
            "Epoch5, train loss : 0.54\n",
            "Epoch5, validation loss : 0.54\n",
            "Epoch6, train loss : 0.54\n",
            "Epoch6, validation loss : 0.53\n",
            "Epoch7, train loss : 0.54\n",
            "Epoch7, validation loss : 0.54\n",
            "Epoch8, train loss : 0.53\n",
            "Epoch8, validation loss : 0.53\n",
            "Epoch9, train loss : 0.53\n",
            "Epoch9, validation loss : 0.53\n",
            "Epoch10, train loss : 0.53\n",
            "Epoch10, validation loss : 0.52\n",
            "Epoch11, train loss : 0.53\n",
            "Epoch11, validation loss : 0.53\n",
            "Epoch12, train loss : 0.52\n",
            "Epoch12, validation loss : 0.52\n",
            "Epoch13, train loss : 0.52\n",
            "Epoch13, validation loss : 0.52\n",
            "Epoch14, train loss : 0.52\n",
            "Epoch14, validation loss : 0.51\n",
            "Epoch15, train loss : 0.52\n",
            "Epoch15, validation loss : 0.52\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXf29FmsIE7k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}