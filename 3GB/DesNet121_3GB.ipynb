{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DesNet121_3GB.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyO34/vgYi2KQesPRM6GbFCe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moh53/Graduation-Project-FMS/blob/NN-models/3GB/DesNet121_3GB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDrgxb2Muo9H"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEKq41oWvGi2"
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YreXl9zNvOxT"
      },
      "source": [
        "!kaggle datasets download -d paultimothymooney/breast-histopathology-images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2i4FkLl-vRzq"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = \"breast-histopathology-images.zip\"\n",
        "with ZipFile(file_name, 'r')as zip:\n",
        "  data= zip.extractall()\n",
        "  print('Done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcTcymN4vcf1"
      },
      "source": [
        "# Import Libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tarfile\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import time\n",
        "#from torchviz import make_dot\n",
        "#import hiddenlayer as hl\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as tt\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision import transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "project_name='Breast-Cancer-Classification-Logistic-Regression-No-Augmentation'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhD-IwvBvyFh"
      },
      "source": [
        "# Data Transform\n",
        "train_tfms = tt.Compose([tt.ToTensor()])\n",
        "valid_tfms = tt.Compose([tt.ToTensor()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Yu9K9mQv-9K"
      },
      "source": [
        "# Load all image data\n",
        "data_dir = '/content/'\n",
        "folder_name = \"IDC_regular_ps50_idx5\"\n",
        "image_folders = os.path.join(data_dir, folder_name)\n",
        "\n",
        "transform = transforms.Compose([transforms.Resize((50, 50)), transforms.ToTensor()])\n",
        "images = []\n",
        "for file in os.listdir(image_folders):\n",
        "    images.append(ImageFolder(os.path.join(image_folders, file), transform=transform))\n",
        "datasets = torch.utils.data.ConcatDataset(images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4Niw-O1wjHy"
      },
      "source": [
        "# Prepare data for training, validation and test\n",
        "random_seed = 42\n",
        "torch.manual_seed(random_seed)\n",
        "\n",
        "test_size = 38000\n",
        "train_size = len(datasets) - test_size\n",
        "train_ds, test_ds = random_split(datasets, [train_size, test_size])\n",
        "\n",
        "val_size = 38000\n",
        "train_size = len(train_ds) - val_size\n",
        "train_ds, val_ds = random_split(train_ds, [train_size, val_size])\n",
        "\n",
        "len(train_ds), len(val_ds), len(test_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xinUVLdRw7QV"
      },
      "source": [
        "train_loader = DataLoader(train_ds, batch_size=400, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_data = DataLoader(val_ds, batch_size=400, shuffle=True, num_workers=4, pin_memory=True)\n",
        "test_loader = DataLoader(test_ds, batch_size=400, shuffle=True, num_workers=4, pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oWVASD5w_Q-"
      },
      "source": [
        "model = models.densenet121(pretrained = True) \n",
        "model "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hELwsyPXxiq6"
      },
      "source": [
        "for params in model.parameters(): \n",
        "    params.requires_grad = False \n",
        "\n",
        "from collections import OrderedDict \n",
        " \n",
        "classifier = nn.Sequential(OrderedDict([ \n",
        "    ('fc1',nn.Linear(1024,500)), \n",
        "    ('relu',nn.ReLU()), \n",
        "    ('fc2',nn.Linear(500,2)), \n",
        "    ('Output',nn.LogSoftmax(dim=1)) \n",
        "])) \n",
        " \n",
        "model.classifier = classifier "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ox6H32FyQFnL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQTi4EBLxprT"
      },
      "source": [
        "model = model.cuda() \n",
        "optimizer= torch.optim.Adam(model.classifier.parameters()) \n",
        "criterian= nn.NLLLoss() \n",
        "list_train_loss=[] \n",
        "list_test_loss=[] \n",
        " \n",
        "for epoch in range(10): \n",
        "    train_loss= 0 \n",
        "    test_loss= 0 \n",
        "    for bat,(img,label) in enumerate(train_loader): \n",
        "        # moving batch and labels to gpu \n",
        "        img = img.to('cuda:0') \n",
        "        label = label.to('cuda:0') \n",
        "        model.train() \n",
        "        optimizer.zero_grad() \n",
        " \n",
        "        output = model(img) \n",
        "        loss = criterian(output,label) \n",
        "        loss.backward() \n",
        "        optimizer.step() \n",
        "        train_loss = train_loss+loss.item() \n",
        " \n",
        "    accuracy=0 \n",
        "    for bat,(img,label) in enumerate(test_loader): \n",
        "        img = img.to('cuda:0') \n",
        "        label = label.to('cuda:0') \n",
        "        model.eval() \n",
        "        logps= model(img) \n",
        "        loss = criterian(logps,label) \n",
        "        test_loss+= loss.item() \n",
        "        ps=torch.exp(logps) \n",
        "        top_ps,top_class=ps.topk(1,dim=1) \n",
        "        equality=top_class == label.view(*top_class.shape) \n",
        "        accuracy +=torch.mean(equality.type(torch.FloatTensor)).item() \n",
        " \n",
        "    list_train_loss.append(train_loss/20) \n",
        "    list_test_loss.append(test_loss/20) \n",
        "    print('epoch: ',epoch,' train_loss: ',train_loss/20,' test_loss: ',test_loss/20,' accuracy: ', accuracy/len(test_loader)) \n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cz6ulJgFx2nH"
      },
      "source": [
        "samples, _ = iter(test_loader).next() \n",
        "samples = samples.to('cuda:0') \n",
        "fig = plt.figure(figsize=(24, 16)) \n",
        "fig.tight_layout() \n",
        "output = model(samples[:24]) \n",
        "pred = torch.argmax(output, dim=1) \n",
        "pred = [p.item() for p in pred] \n",
        "ad = {0:'I guess it\\'s 0', 1:'I guess it\\'s a 1'} \n",
        "for num, sample in enumerate(samples[:24]): \n",
        "    plt.subplot(4,6,num+1) \n",
        "    plt.title(ad[pred[num]]) \n",
        "    plt.axis('off') \n",
        "    sample = sample.cpu().numpy() \n",
        "    plt.imshow(np.transpose(sample, (1,2,0))) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OPzrdgZyxZK"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "figs , ax = plt.subplots(1,2,figsize=(20,5)) \n",
        "ax[0].plot(list_test_loss) \n",
        "ax[0].set_title('test_loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsgvoszhyxWR"
      },
      "source": [
        " "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}