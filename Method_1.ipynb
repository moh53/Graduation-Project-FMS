{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Method 1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moh53/Graduation-Project-FMS/blob/main/Method_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***load Kaggle breast cancer datase***"
      ],
      "metadata": {
        "id": "BT_JlC3klkAj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TaHQ7nRyC0m"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "9bkoCI8uyOlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d paultimothymooney/breast-histopathology-images"
      ],
      "metadata": {
        "id": "UiZZCFSoyOi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = \"breast-histopathology-images.zip\"\n",
        "with ZipFile(file_name, 'r')as zip:\n",
        "  data= zip.extractall()\n",
        "  print('Done')"
      ],
      "metadata": {
        "id": "8FJq4evsyOhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***import Liberary ***"
      ],
      "metadata": {
        "id": "xLfh-nb3lpgv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tarfile\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as tt\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision import transforms\n",
        "from collections import Counter\n",
        "\n",
        "import torchvision .transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import WeightedRandomSampler"
      ],
      "metadata": {
        "id": "vKhjw15qyOfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchstain\n",
        "import torchstain"
      ],
      "metadata": {
        "id": "pGCvlPNPyOd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load all image data\n",
        "data_dir = os.getcwd()\n",
        "folder_name = \"IDC_regular_ps50_idx5\"\n",
        "image_folders = os.path.join(data_dir, folder_name)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "                      transforms.RandomRotation(15),\n",
        "                      \n",
        "                      transforms.Resize((100, 100)),\n",
        "                      transforms.ToTensor(),transforms.Lambda(lambda x: x*255),\n",
        "                      transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "                      transforms.ColorJitter(brightness=0, contrast=0, saturation=0, hue=0)])\n",
        "torch_normalizer = torchstain.MacenkoNormalizer(backend='torch')\n",
        "\n",
        "\n",
        "images = []\n",
        "for file in os.listdir(image_folders):\n",
        "    images.append(ImageFolder(os.path.join(image_folders, file), transform=transform))\n",
        "datasets = torch.utils.data.ConcatDataset(images)"
      ],
      "metadata": {
        "id": "k9JOScGqyOcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Prepare data for training, validation and test***"
      ],
      "metadata": {
        "id": "C5AXvarDly2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data for training, validation and test\n",
        "random_seed = 42\n",
        "torch.manual_seed(random_seed)\n",
        "\n",
        "test_size = 38000\n",
        "train_size = len(datasets) - test_size\n",
        "train_ds, test_ds = random_split(datasets, [train_size, test_size])\n",
        "\n",
        "val_size = 38000\n",
        "train_size = len(train_ds) - val_size\n",
        "train_ds, val_ds = random_split(train_ds, [train_size, val_size])\n",
        "\n",
        "len(train_ds), len(val_ds), len(test_ds)"
      ],
      "metadata": {
        "id": "01yFLyNfyOZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine the number of samples for each class\n",
        "i=0\n",
        "for dataset in datasets.datasets:\n",
        "    if i==0:\n",
        "        result = Counter(dataset.targets)\n",
        "        i += 1\n",
        "    else:\n",
        "        result += Counter(dataset.targets)\n",
        "\n",
        "result = dict(result)\n",
        "print(\"\"\"Total Number of Images for each Class:\n",
        "    Class 0 (No Breast Cancer): {}\n",
        "    Class 1 (Breast Cancer present): {}\"\"\".format(result[0], result[1]))"
      ],
      "metadata": {
        "id": "v0dhzoLTywzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pie chart (Number of Samples For Each Class)\n",
        "labels = \"0: benign (No Cancer)\", \"1: malignant (Have Cancer)\"\n",
        "total = result[0] + result[1]\n",
        "sizes = [result[0]/total, result[1]/total]\n",
        "explode = (0, 0.1)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n",
        "\n",
        "fig1, ax1 = plt.subplots()\n",
        "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n",
        "        shadow=True, startangle=90)\n",
        "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
        "plt.title(\"Number of Samples by Class\")\n",
        "plt.show()\n",
        "plt.savefig(\"number_of_samples_breakdown\")"
      ],
      "metadata": {
        "id": "3oaojkAMyOWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Traning without Oversampling technique ***"
      ],
      "metadata": {
        "id": "m1uCLSy7zQak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = DataLoader(train_ds, shuffle=True, num_workers=4, pin_memory=True, batch_size= 200)\n",
        "val_data = DataLoader(val_ds, shuffle=True, num_workers=4, pin_memory=True, batch_size= 200)\n",
        "test_data = DataLoader(test_ds, shuffle=True, num_workers=4, pin_memory=True, batch_size= 200)"
      ],
      "metadata": {
        "id": "cm7cYQkAyOT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***ResNet50 without OverSampling***"
      ],
      "metadata": {
        "id": "sgQvVupB1zGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() \n",
        "                                  else \"cpu\")\n",
        "model = models.resnet50(pretrained=True)\n",
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ],
      "metadata": {
        "id": "G60hVa3zz37G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "model.fc = nn.Sequential(nn.Linear(2048, 512),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Dropout(0.2),\n",
        "                                 nn.Linear(512, 2),\n",
        "                                 nn.LogSoftmax(dim=1))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.003)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "1KVq8_4qz3kR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 10\n",
        "print_every = 100\n",
        "valid_loss_min = np.Inf\n",
        "val_loss = []\n",
        "val_acc = []\n",
        "train_loss = []\n",
        "train_acc = []\n",
        "total_step = len(train_data)\n",
        "for epoch in range(1, n_epochs+1):\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total=0\n",
        "    print(f'Epoch {epoch}\\n')\n",
        "    for batch_idx, (data_, target_) in enumerate(train_data):\n",
        "        \n",
        "        data_ = data_.to(device)\n",
        "        target_ = target_.to(device)\n",
        "        #batch_idx = batch_idx.to(device)  #this will move inout to your device        \n",
        "        #batch = batch.to(device)  #this will move inout to your device        \n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        outputs = model(data_)\n",
        "        loss = criterion(outputs, target_)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _,pred = torch.max(outputs, dim=1)\n",
        "        correct += torch.sum(pred==target_).item()\n",
        "        total += target_.size(0)\n",
        "        if (batch_idx) % 200 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch, n_epochs, batch_idx, total_step, loss.item()))\n",
        "    train_acc.append(100 * correct / total)\n",
        "    train_loss.append(running_loss/total_step)\n",
        "    print(f'\\ntrain-loss: {np.mean(train_loss):.4f}, train-acc: {(100 * correct/total):.4f}')\n",
        "    batch_loss = 0\n",
        "    total_t=0\n",
        "    correct_t=0\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for data_t, target_t in (val_data):\n",
        "            data_t, target_t = data_t.to(device), target_t.to(device)\n",
        "            outputs_t = model(data_t)\n",
        "            loss_t = criterion(outputs_t, target_t)\n",
        "            batch_loss += loss_t.item()\n",
        "            _,pred_t = torch.max(outputs_t, dim=1)\n",
        "            correct_t += torch.sum(pred_t==target_t).item()\n",
        "            total_t += target_t.size(0)\n",
        "        val_acc.append(100 * correct_t/total_t)\n",
        "        val_loss.append(batch_loss/len(val_data))\n",
        "        network_learned = batch_loss < valid_loss_min\n",
        "        print(f'validation loss: {np.mean(val_loss):.4f}, validation acc: {(100 * correct_t/total_t):.4f}\\n')\n",
        "\n",
        "        \n",
        "        if network_learned:\n",
        "            valid_loss_min = batch_loss\n",
        "            torch.save(model.state_dict(), 'resnet.pt')\n",
        "            print('Improvement-Detected, save-model')\n",
        "    model.train()"
      ],
      "metadata": {
        "id": "UIeeg9iR2K3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ResNet50 Performance**"
      ],
      "metadata": {
        "id": "MrQ7pPjG2YVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        " \n",
        "y_pred = []\n",
        "y_true = []\n",
        " \n",
        "# iterate over test data\n",
        "for inputs, labels in test_data: \n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        output = model(inputs) # Feed Network\n",
        " \n",
        "        output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
        "        y_pred.extend(output) # Save Prediction\n",
        "        \n",
        "        labels = labels.data.cpu().numpy()\n",
        "        y_true.extend(labels) # Save Truth\n",
        " \n",
        "# constant for classes\n",
        "classes = ('negative', 'posative')\n",
        "\n",
        "print(precision_score(y_true, y_pred))\n",
        "print(recall_score(y_true, y_pred))\n",
        "# Build confusion matrix\n",
        "cf_matrix = confusion_matrix(y_true, y_pred)\n",
        "df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix) *10, index = [i for i in classes],\n",
        "                     columns = [i for i in classes])\n",
        "plt.figure(figsize = (12,7))\n",
        "sn.heatmap(df_cm, annot=True)\n",
        "plt.savefig('output.png')"
      ],
      "metadata": {
        "id": "rNbQZahh2Kxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(train_acc, color='green', label='train accuracy')\n",
        "plt.plot(val_acc, color='blue', label='validataion accuracy')\n",
        "plt.legend()\n",
        "plt.savefig('accuracy.png')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "nnxZ3nqq2TkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(train_loss, color='green', label='train loss')\n",
        "plt.plot(val_loss, color='blue', label='validataion loss')\n",
        "plt.legend()\n",
        "plt.savefig('loss.png')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "y0Ian9hh2WBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ResNet18 without oversampling**"
      ],
      "metadata": {
        "id": "l18NOCvv2hcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() \n",
        "                                  else \"cpu\")\n",
        "model = models.resnet18(pretrained=True)\n",
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ],
      "metadata": {
        "id": "8fR78-PD2tL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "model.fc = nn.Sequential(nn.Linear(512, 512),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Dropout(0.2),\n",
        "                                 nn.Linear(512, 2),\n",
        "                                 nn.LogSoftmax(dim=1))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.003)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "0pIngc0l2tJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 10\n",
        "print_every = 100\n",
        "valid_loss_min = np.Inf\n",
        "val_loss = []\n",
        "val_acc = []\n",
        "train_loss = []\n",
        "train_acc = []\n",
        "total_step = len(train_data)\n",
        "for epoch in range(1, n_epochs+1):\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total=0\n",
        "    print(f'Epoch {epoch}\\n')\n",
        "    for batch_idx, (data_, target_) in enumerate(train_data):\n",
        "        \n",
        "        data_ = data_.to(device)\n",
        "        target_ = target_.to(device)\n",
        "        #batch_idx = batch_idx.to(device)  #this will move inout to your device        \n",
        "        #batch = batch.to(device)  #this will move inout to your device        \n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        outputs = model(data_)\n",
        "        loss = criterion(outputs, target_)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _,pred = torch.max(outputs, dim=1)\n",
        "        correct += torch.sum(pred==target_).item()\n",
        "        total += target_.size(0)\n",
        "        if (batch_idx) % 200 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch, n_epochs, batch_idx, total_step, loss.item()))\n",
        "    train_acc.append(100 * correct / total)\n",
        "    train_loss.append(running_loss/total_step)\n",
        "    print(f'\\ntrain-loss: {np.mean(train_loss):.4f}, train-acc: {(100 * correct/total):.4f}')\n",
        "    batch_loss = 0\n",
        "    total_t=0\n",
        "    correct_t=0\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for data_t, target_t in (val_data):\n",
        "            data_t, target_t = data_t.to(device), target_t.to(device)\n",
        "            outputs_t = model(data_t)\n",
        "            loss_t = criterion(outputs_t, target_t)\n",
        "            batch_loss += loss_t.item()\n",
        "            _,pred_t = torch.max(outputs_t, dim=1)\n",
        "            correct_t += torch.sum(pred_t==target_t).item()\n",
        "            total_t += target_t.size(0)\n",
        "        val_acc.append(100 * correct_t/total_t)\n",
        "        val_loss.append(batch_loss/len(val_data))\n",
        "        network_learned = batch_loss < valid_loss_min\n",
        "        print(f'validation loss: {np.mean(val_loss):.4f}, validation acc: {(100 * correct_t/total_t):.4f}\\n')\n",
        "\n",
        "        \n",
        "        if network_learned:\n",
        "            valid_loss_min = batch_loss\n",
        "            torch.save(model.state_dict(), 'resnet.pt')\n",
        "            print('Improvement-Detected, save-model')\n",
        "    model.train()"
      ],
      "metadata": {
        "id": "d6Mh-NYc2tGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ResNet18 Performance**"
      ],
      "metadata": {
        "id": "zEnLApEb3K81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        " \n",
        "y_pred = []\n",
        "y_true = []\n",
        " \n",
        "# iterate over test data\n",
        "for inputs, labels in test_data: \n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        output = model(inputs) # Feed Network\n",
        " \n",
        "        output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
        "        y_pred.extend(output) # Save Prediction\n",
        "        \n",
        "        labels = labels.data.cpu().numpy()\n",
        "        y_true.extend(labels) # Save Truth\n",
        " \n",
        "# constant for classes\n",
        "classes = ('negative', 'posative')\n",
        "\n",
        "print(precision_score(y_true, y_pred))\n",
        "print(recall_score(y_true, y_pred))\n",
        "# Build confusion matrix\n",
        "cf_matrix = confusion_matrix(y_true, y_pred)\n",
        "df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix) *10, index = [i for i in classes],\n",
        "                     columns = [i for i in classes])\n",
        "plt.figure(figsize = (12,7))\n",
        "sn.heatmap(df_cm, annot=True)\n",
        "plt.savefig('output.png')"
      ],
      "metadata": {
        "id": "Tf7PQKuY28ZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(train_acc, color='green', label='train accuracy')\n",
        "plt.plot(val_acc, color='blue', label='validataion accuracy')\n",
        "plt.legend()\n",
        "plt.savefig('accuracy.png')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "aBUG4ajX27_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(train_loss, color='green', label='train loss')\n",
        "plt.plot(val_loss, color='blue', label='validataion loss')\n",
        "plt.legend()\n",
        "plt.savefig('loss.png')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "aqaKR2PZ275g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **VGG16 without oversampling**"
      ],
      "metadata": {
        "id": "d1ijaM_Z3SMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.onnx as onnx\n",
        "import torchvision.models as models\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() \n",
        "                                  else \"cpu\")\n",
        "vgg16 = models.vgg16(pretrained=True)\n",
        "torch.save(vgg16.state_dict(), 'model_weights.pth')"
      ],
      "metadata": {
        "id": "KOAGRzwe3R9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change the number of classes \n",
        "vgg16.classifier[6].out_features = 2\n",
        "# freeze convolution weights\n",
        "for param in vgg16.features.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "Jli_OBX-3R50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "# optimizer\n",
        "optimizer = optim.Adam(vgg16.classifier.parameters(), lr=0.001)\n",
        "# loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "model = vgg16.to(device)"
      ],
      "metadata": {
        "id": "UjVTOQe23Rte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 10\n",
        "print_every = 100\n",
        "valid_loss_min = np.Inf\n",
        "val_loss = []\n",
        "val_acc = []\n",
        "train_loss = []\n",
        "train_acc = []\n",
        "total_step = len(train_data)\n",
        "for epoch in range(1, n_epochs+1):\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total=0\n",
        "    print(f'Epoch {epoch}\\n')\n",
        "    for batch_idx, (data_, target_) in enumerate(train_data):\n",
        "        \n",
        "        data_ = data_.to(device)\n",
        "        target_ = target_.to(device)\n",
        "        #batch_idx = batch_idx.to(device)  #this will move inout to your device        \n",
        "        #batch = batch.to(device)  #this will move inout to your device        \n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        outputs = model(data_)\n",
        "        loss = criterion(outputs, target_)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _,pred = torch.max(outputs, dim=1)\n",
        "        correct += torch.sum(pred==target_).item()\n",
        "        total += target_.size(0)\n",
        "        if (batch_idx) % 200 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch, n_epochs, batch_idx, total_step, loss.item()))\n",
        "    train_acc.append(100 * correct / total)\n",
        "    train_loss.append(running_loss/total_step)\n",
        "    print(f'\\ntrain-loss: {np.mean(train_loss):.4f}, train-acc: {(100 * correct/total):.4f}')\n",
        "    batch_loss = 0\n",
        "    total_t=0\n",
        "    correct_t=0\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for data_t, target_t in (val_data):\n",
        "            data_t, target_t = data_t.to(device), target_t.to(device)\n",
        "            outputs_t = model(data_t)\n",
        "            loss_t = criterion(outputs_t, target_t)\n",
        "            batch_loss += loss_t.item()\n",
        "            _,pred_t = torch.max(outputs_t, dim=1)\n",
        "            correct_t += torch.sum(pred_t==target_t).item()\n",
        "            total_t += target_t.size(0)\n",
        "        val_acc.append(100 * correct_t/total_t)\n",
        "        val_loss.append(batch_loss/len(val_data))\n",
        "        network_learned = batch_loss < valid_loss_min\n",
        "        print(f'validation loss: {np.mean(val_loss):.4f}, validation acc: {(100 * correct_t/total_t):.4f}\\n')\n",
        "\n",
        "        \n",
        "        if network_learned:\n",
        "            valid_loss_min = batch_loss\n",
        "            torch.save(model.state_dict(), 'resnet.pt')\n",
        "            print('Improvement-Detected, save-model')\n",
        "    model.train()"
      ],
      "metadata": {
        "id": "jMKPytdI4LPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **VGG Performance**"
      ],
      "metadata": {
        "id": "v1T9raI34dLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(train_acc, color='green', label='train accuracy')\n",
        "plt.plot(val_acc, color='blue', label='validataion accuracy')\n",
        "plt.legend()\n",
        "plt.savefig('accuracy.png')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1YtGHx8e4YVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(train_loss, color='green', label='train loss')\n",
        "plt.plot(val_loss, color='blue', label='validataion loss')\n",
        "plt.legend()\n",
        "plt.savefig('loss.png')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "J2zK743C4YQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Traning on Oversampeled preprocessing***"
      ],
      "metadata": {
        "id": "uhtlTJdtzl_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_seed = 42\n",
        "torch.manual_seed(random_seed)\n",
        "class_weights = [1, 3]\n",
        "sample_weights = [0] * len(train_ds)\n",
        "for idx, (data, label) in enumerate(train_ds):\n",
        "    class_weight = class_weights[label]\n",
        "    sample_weights[idx] = class_weight\n",
        "sampler = WeightedRandomSampler(sample_weights, num_samples= len(sample_weights), replacement= True)\n",
        "train_data = DataLoader(train_ds, batch_size= 200, sampler=sampler)"
      ],
      "metadata": {
        "id": "esM-jp0UyOSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_posative = 0\n",
        "num_negative = 0\n",
        "for data, label in train_data:\n",
        "    num_negative += torch.sum(label==0)\n",
        "    num_posative += torch.sum(label==1)\n",
        "print(num_negative)\n",
        "print(num_posative)"
      ],
      "metadata": {
        "id": "VZjWffgQyOQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_seed = 42\n",
        "torch.manual_seed(random_seed)\n",
        "class_weights = [1, 3]\n",
        "sample_weights = [0] * len(val_ds)\n",
        "for idx, (data, label) in enumerate(val_ds):\n",
        "    class_weight = class_weights[label]\n",
        "    sample_weights[idx] = class_weight\n",
        "sampler = WeightedRandomSampler(sample_weights, num_samples= len(sample_weights), replacement= True)\n",
        "val_data = DataLoader(val_ds, batch_size= 200, sampler=sampler)"
      ],
      "metadata": {
        "id": "SqZ4JMVMyOOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_posative = 0\n",
        "num_negative = 0\n",
        "for data, label in val_data:\n",
        "    num_negative += torch.sum(label==0)\n",
        "    num_posative += torch.sum(label==1)\n",
        "print(num_negative)\n",
        "print(num_posative)"
      ],
      "metadata": {
        "id": "fpW5gEjhyOMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_seed = 42\n",
        "torch.manual_seed(random_seed)\n",
        "class_weights = [1, 3]\n",
        "sample_weights = [0] * len(test_ds)\n",
        "for idx, (data, label) in enumerate(test_ds):\n",
        "    class_weight = class_weights[label]\n",
        "    sample_weights[idx] = class_weight\n",
        "sampler = WeightedRandomSampler(sample_weights, num_samples= len(sample_weights), replacement= True)\n",
        "test_data = DataLoader(test_ds, batch_size= 200, sampler=sampler)"
      ],
      "metadata": {
        "id": "w9-HWiIuyOKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_posative = 0\n",
        "num_negative = 0\n",
        "for data, label in test_data:\n",
        "    num_negative += torch.sum(label==0)\n",
        "    num_posative += torch.sum(label==1)\n",
        "print(num_negative)\n",
        "print(num_posative)"
      ],
      "metadata": {
        "id": "cVmQBN4HzMM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***ResNet50 OVERSAMPLING***"
      ],
      "metadata": {
        "id": "97yaC3gn5iwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(train_loss, color='green', label='train loss')\n",
        "plt.plot(val_loss, color='blue', label='validataion loss')\n",
        "plt.legend()\n",
        "plt.savefig('loss.png')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "63vMhjVs6ViS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***ResNet18 OVERSAMPLING***"
      ],
      "metadata": {
        "id": "MlflFzb05qRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(train_loss, color='green', label='train loss')\n",
        "plt.plot(val_loss, color='blue', label='validataion loss')\n",
        "plt.legend()\n",
        "plt.savefig('loss.png')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "aDTyiCwZ6UlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **VGG16 OVERSAMPLING**"
      ],
      "metadata": {
        "id": "Q-qqFT6p5yNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(train_loss, color='green', label='train loss')\n",
        "plt.plot(val_loss, color='blue', label='validataion loss')\n",
        "plt.legend()\n",
        "plt.savefig('loss.png')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7XhVMw8F6R0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BGfnLKup6Rxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "X_1d7QnK6RtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hjItWqj46RqH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}